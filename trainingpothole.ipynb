{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-9dKzuIjai0",
        "outputId": "474e8531-f07e-4c65-d12c-d69d34719bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.14.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==1.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.12.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement glob (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for glob\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.26.4)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56437 sha256=a5bd53f785f0cdef1b2a6eec6d8a1d31659464507475252dfe14c9183cf71429\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n",
            "Requirement already satisfied: Imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow==1.14.0\n",
        "! pip install keras\n",
        "! pip install h5py\n",
        "! pip install opencv-python\n",
        "! pip install glob\n",
        "! pip install np_utils\n",
        "! pip install Imutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PDQrVemOekU",
        "outputId": "2e003086-2356-4ab5-c7ae-80cd44643f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "train shape X (696, 100, 100, 1)\n",
            "train shape y (696, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.mlab as mlab\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow.contrib.layers import flatten\n",
        "\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Convolution2D, Cropping2D, Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "import time, cv2, glob\n",
        "\n",
        "global inputShape,size\n",
        "\n",
        "def kerasModel4():\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16, (8, 8), strides=(4, 4), padding='valid', input_shape=(size,size,1)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        # model.add(Dropout(.2))\n",
        "        # model.add(Activation('relu'))\n",
        "        # model.add(Dense(1024))\n",
        "        # model.add(Dropout(.5))\n",
        "        model.add(Dense(512))\n",
        "        model.add(Dropout(.1))\n",
        "        model.add(Activation('relu'))\n",
        "        # model.add(Dense(256))\n",
        "        # model.add(Dropout(.5))\n",
        "        # model.add(Activation('relu'))\n",
        "        model.add(Dense(2))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "size=100\n",
        "\n",
        " ## load Training data : pothole\n",
        "potholeTrainImages = glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/train/Pothole/*.jpg\")\n",
        "potholeTrainImages.extend(glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/train/Pothole/*.jpeg\"))\n",
        "potholeTrainImages.extend(glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/train/Pothole/*.png\"))\n",
        "\n",
        "train1 = [cv2.imread(img,0) for img in potholeTrainImages]\n",
        "for i in range(0,len(train1)):\n",
        "    train1[i] = cv2.resize(train1[i],(size,size))\n",
        "temp1 = np.asarray(train1)\n",
        "\n",
        "\n",
        "#  ## load Training data : non-pothole\n",
        "nonPotholeTrainImages = glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/train/Plain/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "train2 = [cv2.imread(img,0) for img in nonPotholeTrainImages]\n",
        "# train2[train2 != np.array(None)]\n",
        "for i in range(0,len(train2)):\n",
        "    train2[i] = cv2.resize(train2[i],(size,size))\n",
        "temp2 = np.asarray(train2)\n",
        "\n",
        "\n",
        "\n",
        "## load Testing data : non-pothole\n",
        "nonPotholeTestImages = glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/test/Plain/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "test2 = [cv2.imread(img,0) for img in nonPotholeTestImages]\n",
        "# train2[train2 != np.array(None)]\n",
        "for i in range(0,len(test2)):\n",
        "    test2[i] = cv2.resize(test2[i],(size,size))\n",
        "temp4 = np.asarray(test2)\n",
        "\n",
        "\n",
        "## load Testing data : potholes\n",
        "potholeTestImages = glob.glob(\"/content/drive/MyDrive/Howard/pothole-detection-system-using-convolution-neural-networks-master/My Dataset/test/Pothole/*.jpg\")\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.jpeg\"))\n",
        "# nonPotholeTrainImages.extend(glob.glob(\"C:/Users/anant/Desktop/pothole-and-plain-rode-images/My Dataset/train/Plain/*.png\"))\n",
        "test1 = [cv2.imread(img,0) for img in potholeTestImages]\n",
        "# train2[train2 != np.array(None)]\n",
        "for i in range(0,len(test1)):\n",
        "    test1[i] = cv2.resize(test1[i],(size,size))\n",
        "temp3 = np.asarray(test1)\n",
        "\n",
        "\n",
        "X_train = []\n",
        "X_train.extend(temp1)\n",
        "X_train.extend(temp2)\n",
        "X_train = np.asarray(X_train)\n",
        "\n",
        "X_test = []\n",
        "X_test.extend(temp3)\n",
        "X_test.extend(temp4)\n",
        "X_test = np.asarray(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y_train1 = np.ones([temp1.shape[0]],dtype = int)\n",
        "y_train2 = np.zeros([temp2.shape[0]],dtype = int)\n",
        "y_test1 = np.ones([temp3.shape[0]],dtype = int)\n",
        "y_test2 = np.zeros([temp4.shape[0]],dtype = int)\n",
        "\n",
        "print(y_train1[0])\n",
        "print(y_train2[0])\n",
        "print(y_test1[0])\n",
        "print(y_test2[0])\n",
        "\n",
        "y_train = []\n",
        "y_train.extend(y_train1)\n",
        "y_train.extend(y_train2)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "y_test = []\n",
        "y_test.extend(y_test1)\n",
        "y_test.extend(y_test2)\n",
        "y_test = np.asarray(y_test)\n",
        "\n",
        "\n",
        "X_train,y_train = shuffle(X_train,y_train)\n",
        "X_test,y_test = shuffle(X_test,y_test)\n",
        "\n",
        "# X_train.reshape([-1,50,50,1])\n",
        "# X_test.reshape([-1,50,50,1])/\n",
        "X_train = X_train.reshape(X_train.shape[0], size, size, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], size, size, 1)\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test =  to_categorical(y_test)\n",
        "\n",
        "\n",
        "print(\"train shape X\", X_train.shape)\n",
        "print(\"train shape y\", y_train.shape)\n",
        "\n",
        "inputShape = (size, size, 1)\n",
        "model = kerasModel4()\n",
        "\n",
        "\n",
        "#model.compile('Adam', 'categorical_crossentropy', ['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g5u3S6SJo80a",
        "outputId": "b63f0410-08e7-4383-fa29-53c1db95ab74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 151ms/step - accuracy: 0.5258 - loss: 1.9261 - val_accuracy: 0.5714 - val_loss: 0.6667\n",
            "Epoch 2/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - accuracy: 0.5386 - loss: 0.7077 - val_accuracy: 0.5857 - val_loss: 0.6750\n",
            "Epoch 3/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.5789 - loss: 0.6779 - val_accuracy: 0.4714 - val_loss: 0.7124\n",
            "Epoch 4/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.5821 - loss: 0.6725 - val_accuracy: 0.5571 - val_loss: 0.6564\n",
            "Epoch 5/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.5989 - loss: 0.6668 - val_accuracy: 0.5429 - val_loss: 0.6531\n",
            "Epoch 6/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.6018 - loss: 0.6543 - val_accuracy: 0.5429 - val_loss: 0.6472\n",
            "Epoch 7/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.6762 - loss: 0.6361 - val_accuracy: 0.6000 - val_loss: 0.6112\n",
            "Epoch 8/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.6714 - loss: 0.6190 - val_accuracy: 0.6000 - val_loss: 0.6479\n",
            "Epoch 9/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6742 - loss: 0.6269 - val_accuracy: 0.7143 - val_loss: 0.6140\n",
            "Epoch 10/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6835 - loss: 0.5829 - val_accuracy: 0.7429 - val_loss: 0.5281\n",
            "Epoch 11/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.7179 - loss: 0.5401 - val_accuracy: 0.6714 - val_loss: 0.5703\n",
            "Epoch 12/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.6249 - loss: 0.6538 - val_accuracy: 0.6286 - val_loss: 0.5761\n",
            "Epoch 13/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.7483 - loss: 0.5582 - val_accuracy: 0.7286 - val_loss: 0.5301\n",
            "Epoch 14/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.6916 - loss: 0.5706 - val_accuracy: 0.5857 - val_loss: 1.3257\n",
            "Epoch 15/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.5013 - loss: 1.0306 - val_accuracy: 0.5857 - val_loss: 0.6657\n",
            "Epoch 16/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6085 - loss: 0.6619 - val_accuracy: 0.5857 - val_loss: 0.6890\n",
            "Epoch 17/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.6782 - loss: 0.6273 - val_accuracy: 0.7286 - val_loss: 0.5848\n",
            "Epoch 18/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7023 - loss: 0.6066 - val_accuracy: 0.6143 - val_loss: 0.6469\n",
            "Epoch 19/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.6904 - loss: 0.6032 - val_accuracy: 0.7286 - val_loss: 0.6267\n",
            "Epoch 20/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.7227 - loss: 0.5768 - val_accuracy: 0.7714 - val_loss: 0.5771\n",
            "Epoch 21/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7367 - loss: 0.5641 - val_accuracy: 0.7143 - val_loss: 0.5168\n",
            "Epoch 22/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7285 - loss: 0.5465 - val_accuracy: 0.7286 - val_loss: 0.5492\n",
            "Epoch 23/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6906 - loss: 0.5598 - val_accuracy: 0.7714 - val_loss: 0.5728\n",
            "Epoch 24/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.7418 - loss: 0.5230 - val_accuracy: 0.7714 - val_loss: 0.5563\n",
            "Epoch 25/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7471 - loss: 0.5315 - val_accuracy: 0.8000 - val_loss: 0.5020\n",
            "Epoch 26/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.8019 - loss: 0.4490 - val_accuracy: 0.7286 - val_loss: 0.4525\n",
            "Epoch 27/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.7153 - loss: 0.5352 - val_accuracy: 0.8286 - val_loss: 0.4659\n",
            "Epoch 28/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.8009 - loss: 0.4579 - val_accuracy: 0.6857 - val_loss: 0.5874\n",
            "Epoch 29/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7947 - loss: 0.4296 - val_accuracy: 0.7000 - val_loss: 0.6172\n",
            "Epoch 30/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.8018 - loss: 0.4413 - val_accuracy: 0.7286 - val_loss: 0.5329\n",
            "Epoch 31/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7967 - loss: 0.4251 - val_accuracy: 0.7857 - val_loss: 0.4278\n",
            "Epoch 32/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.7369 - loss: 0.5016 - val_accuracy: 0.8143 - val_loss: 0.4096\n",
            "Epoch 33/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.8212 - loss: 0.3986 - val_accuracy: 0.7857 - val_loss: 0.4572\n",
            "Epoch 34/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.8584 - loss: 0.3472 - val_accuracy: 0.7143 - val_loss: 0.5563\n",
            "Epoch 35/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.8324 - loss: 0.3709 - val_accuracy: 0.7857 - val_loss: 0.5109\n",
            "Epoch 36/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8601 - loss: 0.3524 - val_accuracy: 0.8571 - val_loss: 0.3114\n",
            "Epoch 37/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8403 - loss: 0.3433 - val_accuracy: 0.8429 - val_loss: 0.3421\n",
            "Epoch 38/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8375 - loss: 0.3802 - val_accuracy: 0.8429 - val_loss: 0.3953\n",
            "Epoch 39/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8802 - loss: 0.3233 - val_accuracy: 0.8571 - val_loss: 0.3868\n",
            "Epoch 40/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8848 - loss: 0.2749 - val_accuracy: 0.8714 - val_loss: 0.2769\n",
            "Epoch 41/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8705 - loss: 0.2973 - val_accuracy: 0.8143 - val_loss: 0.4823\n",
            "Epoch 42/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.8230 - loss: 0.3749 - val_accuracy: 0.8857 - val_loss: 0.3793\n",
            "Epoch 43/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.8610 - loss: 0.3272 - val_accuracy: 0.8286 - val_loss: 0.3672\n",
            "Epoch 44/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8634 - loss: 0.3413 - val_accuracy: 0.8429 - val_loss: 0.4065\n",
            "Epoch 45/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8910 - loss: 0.2641 - val_accuracy: 0.6857 - val_loss: 0.6962\n",
            "Epoch 46/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8581 - loss: 0.3403 - val_accuracy: 0.8857 - val_loss: 0.3359\n",
            "Epoch 47/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.8804 - loss: 0.2667 - val_accuracy: 0.9000 - val_loss: 0.3029\n",
            "Epoch 48/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8871 - loss: 0.2581 - val_accuracy: 0.8571 - val_loss: 0.3093\n",
            "Epoch 49/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.9089 - loss: 0.2372 - val_accuracy: 0.9143 - val_loss: 0.2994\n",
            "Epoch 50/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.8855 - loss: 0.2379 - val_accuracy: 0.8429 - val_loss: 0.3891\n",
            "Epoch 51/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9219 - loss: 0.2133 - val_accuracy: 0.8000 - val_loss: 0.5079\n",
            "Epoch 52/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9274 - loss: 0.1803 - val_accuracy: 0.8571 - val_loss: 0.3716\n",
            "Epoch 53/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9140 - loss: 0.1789 - val_accuracy: 0.8714 - val_loss: 0.3501\n",
            "Epoch 54/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9190 - loss: 0.2012 - val_accuracy: 0.8571 - val_loss: 0.4033\n",
            "Epoch 55/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9401 - loss: 0.1770 - val_accuracy: 0.9143 - val_loss: 0.2449\n",
            "Epoch 56/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9271 - loss: 0.1829 - val_accuracy: 0.8000 - val_loss: 0.6508\n",
            "Epoch 57/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9233 - loss: 0.1998 - val_accuracy: 0.8857 - val_loss: 0.4119\n",
            "Epoch 58/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.9407 - loss: 0.1713 - val_accuracy: 0.8286 - val_loss: 0.5969\n",
            "Epoch 59/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9510 - loss: 0.1308 - val_accuracy: 0.8857 - val_loss: 0.3026\n",
            "Epoch 60/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8813 - loss: 0.2319 - val_accuracy: 0.8857 - val_loss: 0.3829\n",
            "Epoch 61/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9377 - loss: 0.1448 - val_accuracy: 0.8857 - val_loss: 0.3413\n",
            "Epoch 62/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 0.9545 - loss: 0.1490 - val_accuracy: 0.7000 - val_loss: 0.9751\n",
            "Epoch 63/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.8945 - loss: 0.2544 - val_accuracy: 0.8000 - val_loss: 0.4232\n",
            "Epoch 64/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.8659 - loss: 0.3273 - val_accuracy: 0.8143 - val_loss: 0.4557\n",
            "Epoch 65/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9208 - loss: 0.2138 - val_accuracy: 0.8143 - val_loss: 0.5417\n",
            "Epoch 66/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9469 - loss: 0.1508 - val_accuracy: 0.8429 - val_loss: 0.4252\n",
            "Epoch 67/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9533 - loss: 0.1352 - val_accuracy: 0.8571 - val_loss: 0.4684\n",
            "Epoch 68/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9455 - loss: 0.1461 - val_accuracy: 0.8714 - val_loss: 0.3894\n",
            "Epoch 69/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9134 - loss: 0.2157 - val_accuracy: 0.8286 - val_loss: 0.6897\n",
            "Epoch 70/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9369 - loss: 0.1841 - val_accuracy: 0.8429 - val_loss: 0.5009\n",
            "Epoch 71/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9748 - loss: 0.0999 - val_accuracy: 0.8286 - val_loss: 0.6016\n",
            "Epoch 72/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9621 - loss: 0.1026 - val_accuracy: 0.8286 - val_loss: 0.7707\n",
            "Epoch 73/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9616 - loss: 0.0874 - val_accuracy: 0.8429 - val_loss: 0.5367\n",
            "Epoch 74/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9685 - loss: 0.0880 - val_accuracy: 0.8286 - val_loss: 0.6000\n",
            "Epoch 75/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9655 - loss: 0.1029 - val_accuracy: 0.8857 - val_loss: 0.3318\n",
            "Epoch 76/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9575 - loss: 0.1382 - val_accuracy: 0.7429 - val_loss: 0.9775\n",
            "Epoch 77/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9508 - loss: 0.1193 - val_accuracy: 0.7429 - val_loss: 0.9992\n",
            "Epoch 78/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.9737 - loss: 0.0890 - val_accuracy: 0.8571 - val_loss: 0.6112\n",
            "Epoch 79/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.9773 - loss: 0.0612 - val_accuracy: 0.8714 - val_loss: 0.6814\n",
            "Epoch 80/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9880 - loss: 0.0532 - val_accuracy: 0.8857 - val_loss: 0.4206\n",
            "Epoch 81/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9843 - loss: 0.0534 - val_accuracy: 0.8857 - val_loss: 0.5620\n",
            "Epoch 82/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9974 - loss: 0.0378 - val_accuracy: 0.8714 - val_loss: 0.6343\n",
            "Epoch 83/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9857 - loss: 0.0473 - val_accuracy: 0.8571 - val_loss: 0.6833\n",
            "Epoch 84/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9791 - loss: 0.0453 - val_accuracy: 0.8714 - val_loss: 0.6223\n",
            "Epoch 85/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9966 - loss: 0.0298 - val_accuracy: 0.8143 - val_loss: 0.8441\n",
            "Epoch 86/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.9987 - loss: 0.0263 - val_accuracy: 0.8714 - val_loss: 0.4147\n",
            "Epoch 87/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9871 - loss: 0.0484 - val_accuracy: 0.8857 - val_loss: 0.5256\n",
            "Epoch 88/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9856 - loss: 0.0429 - val_accuracy: 0.8714 - val_loss: 0.7125\n",
            "Epoch 89/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9836 - loss: 0.0333 - val_accuracy: 0.8429 - val_loss: 0.8534\n",
            "Epoch 90/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9940 - loss: 0.0419 - val_accuracy: 0.8714 - val_loss: 0.7226\n",
            "Epoch 91/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9535 - loss: 0.1232 - val_accuracy: 0.8429 - val_loss: 0.6277\n",
            "Epoch 92/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9157 - loss: 0.2142 - val_accuracy: 0.8571 - val_loss: 0.6199\n",
            "Epoch 93/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.9678 - loss: 0.0992 - val_accuracy: 0.8571 - val_loss: 0.7120\n",
            "Epoch 94/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9870 - loss: 0.0465 - val_accuracy: 0.8714 - val_loss: 0.7520\n",
            "Epoch 95/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9972 - loss: 0.0279 - val_accuracy: 0.8714 - val_loss: 0.6163\n",
            "Epoch 96/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9943 - loss: 0.0259 - val_accuracy: 0.8714 - val_loss: 0.7561\n",
            "Epoch 97/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9995 - loss: 0.0134 - val_accuracy: 0.8571 - val_loss: 0.7100\n",
            "Epoch 98/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9977 - loss: 0.0160 - val_accuracy: 0.8714 - val_loss: 0.6820\n",
            "Epoch 99/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9964 - loss: 0.0150 - val_accuracy: 0.8429 - val_loss: 0.8708\n",
            "Epoch 100/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9994 - loss: 0.0125 - val_accuracy: 0.8571 - val_loss: 0.7906\n",
            "Epoch 101/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.9998 - loss: 0.0100 - val_accuracy: 0.8571 - val_loss: 0.8291\n",
            "Epoch 102/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9997 - loss: 0.0070 - val_accuracy: 0.8429 - val_loss: 1.0652\n",
            "Epoch 103/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9994 - loss: 0.0138 - val_accuracy: 0.8571 - val_loss: 0.5974\n",
            "Epoch 104/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8429 - val_loss: 0.9650\n",
            "Epoch 105/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9946 - loss: 0.0131 - val_accuracy: 0.8571 - val_loss: 0.7850\n",
            "Epoch 106/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8714 - val_loss: 0.8905\n",
            "Epoch 107/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.8429 - val_loss: 0.8545\n",
            "Epoch 108/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8571 - val_loss: 0.9665\n",
            "Epoch 109/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8714 - val_loss: 0.6714\n",
            "Epoch 110/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.8429 - val_loss: 1.0852\n",
            "Epoch 111/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.8714 - val_loss: 0.7984\n",
            "Epoch 112/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.8714 - val_loss: 0.7233\n",
            "Epoch 113/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8714 - val_loss: 0.7809\n",
            "Epoch 114/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.8714 - val_loss: 0.8703\n",
            "Epoch 115/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.8429 - val_loss: 1.1576\n",
            "Epoch 116/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9997 - loss: 0.0061 - val_accuracy: 0.8286 - val_loss: 1.2038\n",
            "Epoch 117/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.9684 - loss: 0.0547 - val_accuracy: 0.8857 - val_loss: 0.5215\n",
            "Epoch 118/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9407 - loss: 0.1944 - val_accuracy: 0.8571 - val_loss: 0.7418\n",
            "Epoch 119/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9611 - loss: 0.0953 - val_accuracy: 0.9000 - val_loss: 0.6874\n",
            "Epoch 120/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 0.9435 - loss: 0.1264 - val_accuracy: 0.8571 - val_loss: 0.4501\n",
            "Epoch 121/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9460 - loss: 0.1110 - val_accuracy: 0.8571 - val_loss: 0.5789\n",
            "Epoch 122/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9948 - loss: 0.0302 - val_accuracy: 0.8429 - val_loss: 0.9651\n",
            "Epoch 123/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9985 - loss: 0.0197 - val_accuracy: 0.8571 - val_loss: 0.8904\n",
            "Epoch 124/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 0.9984 - loss: 0.0102 - val_accuracy: 0.8571 - val_loss: 0.7258\n",
            "Epoch 125/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9968 - loss: 0.0132 - val_accuracy: 0.8429 - val_loss: 0.9137\n",
            "Epoch 126/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9921 - loss: 0.0202 - val_accuracy: 0.8571 - val_loss: 1.1542\n",
            "Epoch 127/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.8429 - val_loss: 1.1904\n",
            "Epoch 128/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9768 - loss: 0.0631 - val_accuracy: 0.6429 - val_loss: 2.2184\n",
            "Epoch 129/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9509 - loss: 0.1334 - val_accuracy: 0.8714 - val_loss: 0.7165\n",
            "Epoch 130/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9740 - loss: 0.0711 - val_accuracy: 0.8429 - val_loss: 0.8013\n",
            "Epoch 131/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9841 - loss: 0.0448 - val_accuracy: 0.8286 - val_loss: 0.8703\n",
            "Epoch 132/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.9934 - loss: 0.0288 - val_accuracy: 0.7857 - val_loss: 1.4329\n",
            "Epoch 133/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.9932 - loss: 0.0213 - val_accuracy: 0.8571 - val_loss: 0.6576\n",
            "Epoch 134/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9851 - loss: 0.0366 - val_accuracy: 0.8857 - val_loss: 0.6538\n",
            "Epoch 135/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9869 - loss: 0.0249 - val_accuracy: 0.8286 - val_loss: 1.1754\n",
            "Epoch 136/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.8143 - val_loss: 1.2273\n",
            "Epoch 137/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8429 - val_loss: 1.0648\n",
            "Epoch 138/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9946 - loss: 0.0076 - val_accuracy: 0.8429 - val_loss: 1.0357\n",
            "Epoch 139/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8429 - val_loss: 1.1763\n",
            "Epoch 140/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.8429 - val_loss: 1.0523\n",
            "Epoch 141/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.8286 - val_loss: 1.0735\n",
            "Epoch 142/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8286 - val_loss: 1.1492\n",
            "Epoch 143/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8429 - val_loss: 1.1241\n",
            "Epoch 144/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8286 - val_loss: 1.0581\n",
            "Epoch 145/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8429 - val_loss: 1.1445\n",
            "Epoch 146/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8429 - val_loss: 1.2756\n",
            "Epoch 147/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8286 - val_loss: 1.0577\n",
            "Epoch 148/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.8429 - val_loss: 1.0437\n",
            "Epoch 149/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8429 - val_loss: 1.1385\n",
            "Epoch 150/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.8286 - val_loss: 1.0992\n",
            "Epoch 151/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8286 - val_loss: 1.1869\n",
            "Epoch 152/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.8286 - val_loss: 1.2237\n",
            "Epoch 153/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8286 - val_loss: 1.1570\n",
            "Epoch 154/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8286 - val_loss: 1.2285\n",
            "Epoch 155/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8286 - val_loss: 1.1743\n",
            "Epoch 156/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 9.7600e-04 - val_accuracy: 0.8429 - val_loss: 1.3035\n",
            "Epoch 157/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 9.7584e-04 - val_accuracy: 0.8429 - val_loss: 1.0959\n",
            "Epoch 158/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8286 - val_loss: 1.1109\n",
            "Epoch 159/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8429 - val_loss: 1.2736\n",
            "Epoch 160/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 8.9270e-04 - val_accuracy: 0.8286 - val_loss: 1.2177\n",
            "Epoch 161/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 9.5808e-04 - val_accuracy: 0.8286 - val_loss: 1.2277\n",
            "Epoch 162/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8429 - val_loss: 1.3084\n",
            "Epoch 163/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 8.9924e-04 - val_accuracy: 0.8286 - val_loss: 1.1894\n",
            "Epoch 164/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 9.2875e-04 - val_accuracy: 0.8429 - val_loss: 1.1329\n",
            "Epoch 165/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.8429 - val_loss: 1.1843\n",
            "Epoch 166/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.1508e-04 - val_accuracy: 0.8429 - val_loss: 1.2890\n",
            "Epoch 167/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 6.6436e-04 - val_accuracy: 0.8286 - val_loss: 1.1086\n",
            "Epoch 168/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8286 - val_loss: 1.1991\n",
            "Epoch 169/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 6.9006e-04 - val_accuracy: 0.8429 - val_loss: 1.0470\n",
            "Epoch 170/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 6.3092e-04 - val_accuracy: 0.8429 - val_loss: 1.3450\n",
            "Epoch 171/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 8.5463e-04 - val_accuracy: 0.8286 - val_loss: 1.1434\n",
            "Epoch 172/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 7.0481e-04 - val_accuracy: 0.8429 - val_loss: 1.2874\n",
            "Epoch 173/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 7.5693e-04 - val_accuracy: 0.8429 - val_loss: 1.2777\n",
            "Epoch 174/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 5.8073e-04 - val_accuracy: 0.8429 - val_loss: 1.2100\n",
            "Epoch 175/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 6.1790e-04 - val_accuracy: 0.8286 - val_loss: 1.2550\n",
            "Epoch 176/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 4.8269e-04 - val_accuracy: 0.8571 - val_loss: 1.2875\n",
            "Epoch 177/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.5368e-04 - val_accuracy: 0.8429 - val_loss: 1.2609\n",
            "Epoch 178/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.0915e-04 - val_accuracy: 0.8571 - val_loss: 1.3060\n",
            "Epoch 179/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 5.1490e-04 - val_accuracy: 0.8429 - val_loss: 1.2789\n",
            "Epoch 180/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 6.2839e-04 - val_accuracy: 0.8429 - val_loss: 1.3295\n",
            "Epoch 181/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 6.3148e-04 - val_accuracy: 0.8571 - val_loss: 1.2931\n",
            "Epoch 182/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 5.4298e-04 - val_accuracy: 0.8429 - val_loss: 1.1531\n",
            "Epoch 183/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 5.3309e-04 - val_accuracy: 0.8571 - val_loss: 1.3380\n",
            "Epoch 184/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.8629e-04 - val_accuracy: 0.8429 - val_loss: 1.4205\n",
            "Epoch 185/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.0709e-04 - val_accuracy: 0.8429 - val_loss: 1.4233\n",
            "Epoch 186/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 6.1265e-04 - val_accuracy: 0.8429 - val_loss: 1.1952\n",
            "Epoch 187/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.7862e-04 - val_accuracy: 0.8571 - val_loss: 1.4145\n",
            "Epoch 188/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 5.9770e-04 - val_accuracy: 0.8571 - val_loss: 1.3428\n",
            "Epoch 189/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 4.3286e-04 - val_accuracy: 0.8429 - val_loss: 1.2779\n",
            "Epoch 190/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 3.8419e-04 - val_accuracy: 0.8571 - val_loss: 1.2960\n",
            "Epoch 191/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 3.6967e-04 - val_accuracy: 0.8571 - val_loss: 1.3787\n",
            "Epoch 192/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.1121e-04 - val_accuracy: 0.8571 - val_loss: 1.3662\n",
            "Epoch 193/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 4.3957e-04 - val_accuracy: 0.8571 - val_loss: 1.3449\n",
            "Epoch 194/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 3.7178e-04 - val_accuracy: 0.8429 - val_loss: 1.2528\n",
            "Epoch 195/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 3.8121e-04 - val_accuracy: 0.8429 - val_loss: 1.3241\n",
            "Epoch 196/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.4143e-04 - val_accuracy: 0.8429 - val_loss: 1.3163\n",
            "Epoch 197/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 3.3879e-04 - val_accuracy: 0.8571 - val_loss: 1.3761\n",
            "Epoch 198/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.3925e-04 - val_accuracy: 0.8429 - val_loss: 1.2727\n",
            "Epoch 199/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 4.5068e-04 - val_accuracy: 0.8429 - val_loss: 1.2734\n",
            "Epoch 200/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.6497e-04 - val_accuracy: 0.8429 - val_loss: 1.4594\n",
            "Epoch 201/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.3324e-04 - val_accuracy: 0.8571 - val_loss: 1.4523\n",
            "Epoch 202/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 2.6879e-04 - val_accuracy: 0.8571 - val_loss: 1.4044\n",
            "Epoch 203/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 3.9031e-04 - val_accuracy: 0.8571 - val_loss: 1.5183\n",
            "Epoch 204/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 3.3569e-04 - val_accuracy: 0.8571 - val_loss: 1.4318\n",
            "Epoch 205/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.3311e-04 - val_accuracy: 0.8571 - val_loss: 1.4347\n",
            "Epoch 206/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.1147e-04 - val_accuracy: 0.8571 - val_loss: 1.4398\n",
            "Epoch 207/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.1303e-04 - val_accuracy: 0.8571 - val_loss: 1.4394\n",
            "Epoch 208/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.2879e-04 - val_accuracy: 0.8571 - val_loss: 1.4164\n",
            "Epoch 209/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.4486e-04 - val_accuracy: 0.8429 - val_loss: 1.3709\n",
            "Epoch 210/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 3.3473e-04 - val_accuracy: 0.8286 - val_loss: 1.3468\n",
            "Epoch 211/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 2.8631e-04 - val_accuracy: 0.8571 - val_loss: 1.4739\n",
            "Epoch 212/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.2024e-04 - val_accuracy: 0.8571 - val_loss: 1.4861\n",
            "Epoch 213/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 2.3752e-04 - val_accuracy: 0.8429 - val_loss: 1.3690\n",
            "Epoch 214/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.7707e-04 - val_accuracy: 0.8571 - val_loss: 1.4144\n",
            "Epoch 215/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.4337e-04 - val_accuracy: 0.8571 - val_loss: 1.4453\n",
            "Epoch 216/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 2.7992e-04 - val_accuracy: 0.8429 - val_loss: 1.3699\n",
            "Epoch 217/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.2629e-04 - val_accuracy: 0.8571 - val_loss: 1.4613\n",
            "Epoch 218/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.2008e-04 - val_accuracy: 0.8429 - val_loss: 1.3385\n",
            "Epoch 219/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.8345e-04 - val_accuracy: 0.8571 - val_loss: 1.4066\n",
            "Epoch 220/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.9359e-04 - val_accuracy: 0.8429 - val_loss: 1.4432\n",
            "Epoch 221/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.2058e-04 - val_accuracy: 0.8571 - val_loss: 1.5023\n",
            "Epoch 222/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.7428e-04 - val_accuracy: 0.8571 - val_loss: 1.4139\n",
            "Epoch 223/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.0589e-04 - val_accuracy: 0.8429 - val_loss: 1.3710\n",
            "Epoch 224/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.7030e-04 - val_accuracy: 0.8571 - val_loss: 1.4800\n",
            "Epoch 225/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 1.6480e-04 - val_accuracy: 0.8571 - val_loss: 1.4397\n",
            "Epoch 226/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.9103e-04 - val_accuracy: 0.8429 - val_loss: 1.3797\n",
            "Epoch 227/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.5441e-04 - val_accuracy: 0.8571 - val_loss: 1.4973\n",
            "Epoch 228/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.9763e-04 - val_accuracy: 0.8429 - val_loss: 1.4422\n",
            "Epoch 229/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.2149e-04 - val_accuracy: 0.8571 - val_loss: 1.4775\n",
            "Epoch 230/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.1999e-04 - val_accuracy: 0.8571 - val_loss: 1.4704\n",
            "Epoch 231/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 2.4240e-04 - val_accuracy: 0.8571 - val_loss: 1.5876\n",
            "Epoch 232/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 1.4812e-04 - val_accuracy: 0.8571 - val_loss: 1.4653\n",
            "Epoch 233/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.4980e-04 - val_accuracy: 0.8571 - val_loss: 1.5361\n",
            "Epoch 234/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.5226e-04 - val_accuracy: 0.8429 - val_loss: 1.4585\n",
            "Epoch 235/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.7467e-04 - val_accuracy: 0.8429 - val_loss: 1.4257\n",
            "Epoch 236/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.3861e-04 - val_accuracy: 0.8571 - val_loss: 1.5298\n",
            "Epoch 237/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.8176e-04 - val_accuracy: 0.8429 - val_loss: 1.4654\n",
            "Epoch 238/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 1.5837e-04 - val_accuracy: 0.8571 - val_loss: 1.5499\n",
            "Epoch 239/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.7461e-04 - val_accuracy: 0.8429 - val_loss: 1.4621\n",
            "Epoch 240/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.7148e-04 - val_accuracy: 0.8571 - val_loss: 1.5807\n",
            "Epoch 241/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0667e-04 - val_accuracy: 0.8571 - val_loss: 1.5184\n",
            "Epoch 242/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.1651e-04 - val_accuracy: 0.8429 - val_loss: 1.4707\n",
            "Epoch 243/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.3757e-04 - val_accuracy: 0.8429 - val_loss: 1.4988\n",
            "Epoch 244/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 1.1259e-04 - val_accuracy: 0.8571 - val_loss: 1.5403\n",
            "Epoch 245/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.4040e-04 - val_accuracy: 0.8571 - val_loss: 1.5476\n",
            "Epoch 246/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 1.6076e-04 - val_accuracy: 0.8571 - val_loss: 1.5489\n",
            "Epoch 247/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.3700e-04 - val_accuracy: 0.8429 - val_loss: 1.5207\n",
            "Epoch 248/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.0927e-04 - val_accuracy: 0.8571 - val_loss: 1.5639\n",
            "Epoch 249/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.4849e-04 - val_accuracy: 0.8571 - val_loss: 1.5896\n",
            "Epoch 250/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.6446e-04 - val_accuracy: 0.8429 - val_loss: 1.5317\n",
            "Epoch 251/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.3714e-04 - val_accuracy: 0.8429 - val_loss: 1.5230\n",
            "Epoch 252/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 1.1416e-04 - val_accuracy: 0.8571 - val_loss: 1.6307\n",
            "Epoch 253/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 9.4490e-05 - val_accuracy: 0.8429 - val_loss: 1.5093\n",
            "Epoch 254/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 1.6491e-04 - val_accuracy: 0.8429 - val_loss: 1.5662\n",
            "Epoch 255/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.3199e-05 - val_accuracy: 0.8429 - val_loss: 1.5601\n",
            "Epoch 256/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.2249e-05 - val_accuracy: 0.8429 - val_loss: 1.5560\n",
            "Epoch 257/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.5568e-04 - val_accuracy: 0.8429 - val_loss: 1.5525\n",
            "Epoch 258/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.3083e-05 - val_accuracy: 0.8571 - val_loss: 1.6046\n",
            "Epoch 259/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.0197e-04 - val_accuracy: 0.8429 - val_loss: 1.5531\n",
            "Epoch 260/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 9.3505e-05 - val_accuracy: 0.8429 - val_loss: 1.5016\n",
            "Epoch 261/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 1.0756e-04 - val_accuracy: 0.8429 - val_loss: 1.5208\n",
            "Epoch 262/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.1367e-04 - val_accuracy: 0.8571 - val_loss: 1.6272\n",
            "Epoch 263/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.1298e-04 - val_accuracy: 0.8571 - val_loss: 1.6315\n",
            "Epoch 264/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 9.0014e-05 - val_accuracy: 0.8429 - val_loss: 1.5021\n",
            "Epoch 265/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.2329e-04 - val_accuracy: 0.8429 - val_loss: 1.5146\n",
            "Epoch 266/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 9.9874e-05 - val_accuracy: 0.8571 - val_loss: 1.6080\n",
            "Epoch 267/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 9.6841e-05 - val_accuracy: 0.8429 - val_loss: 1.5643\n",
            "Epoch 268/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 8.1810e-05 - val_accuracy: 0.8571 - val_loss: 1.5897\n",
            "Epoch 269/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.2126e-04 - val_accuracy: 0.8571 - val_loss: 1.5854\n",
            "Epoch 270/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.5273e-05 - val_accuracy: 0.8571 - val_loss: 1.7210\n",
            "Epoch 271/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.2846e-04 - val_accuracy: 0.8571 - val_loss: 1.6227\n",
            "Epoch 272/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 9.1697e-05 - val_accuracy: 0.8429 - val_loss: 1.5598\n",
            "Epoch 273/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 1.0775e-04 - val_accuracy: 0.8429 - val_loss: 1.6042\n",
            "Epoch 274/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 1.1018e-04 - val_accuracy: 0.8571 - val_loss: 1.7636\n",
            "Epoch 275/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 1.5853e-04 - val_accuracy: 0.8571 - val_loss: 1.5894\n",
            "Epoch 276/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 7.9098e-05 - val_accuracy: 0.8429 - val_loss: 1.5585\n",
            "Epoch 277/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 7.2421e-05 - val_accuracy: 0.8571 - val_loss: 1.5932\n",
            "Epoch 278/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 1.0201e-04 - val_accuracy: 0.8429 - val_loss: 1.5236\n",
            "Epoch 279/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 8.3628e-05 - val_accuracy: 0.8571 - val_loss: 1.6726\n",
            "Epoch 280/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 8.8421e-05 - val_accuracy: 0.8571 - val_loss: 1.6505\n",
            "Epoch 281/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 7.5551e-05 - val_accuracy: 0.8571 - val_loss: 1.6604\n",
            "Epoch 282/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 7.6266e-05 - val_accuracy: 0.8429 - val_loss: 1.5752\n",
            "Epoch 283/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 8.9845e-05 - val_accuracy: 0.8429 - val_loss: 1.6140\n",
            "Epoch 284/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 1.0000 - loss: 8.0014e-05 - val_accuracy: 0.8571 - val_loss: 1.6993\n",
            "Epoch 285/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.6751e-05 - val_accuracy: 0.8429 - val_loss: 1.6325\n",
            "Epoch 286/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 8.2036e-05 - val_accuracy: 0.8571 - val_loss: 1.7110\n",
            "Epoch 287/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 6.5654e-05 - val_accuracy: 0.8429 - val_loss: 1.6313\n",
            "Epoch 288/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 8.5245e-05 - val_accuracy: 0.8571 - val_loss: 1.7831\n",
            "Epoch 289/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 5.4478e-05 - val_accuracy: 0.8571 - val_loss: 1.7266\n",
            "Epoch 290/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 7.4210e-05 - val_accuracy: 0.8571 - val_loss: 1.6916\n",
            "Epoch 291/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 7.1250e-05 - val_accuracy: 0.8571 - val_loss: 1.7604\n",
            "Epoch 292/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 4.8193e-05 - val_accuracy: 0.8571 - val_loss: 1.7361\n",
            "Epoch 293/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 9.1391e-05 - val_accuracy: 0.8429 - val_loss: 1.6691\n",
            "Epoch 294/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 7.0249e-05 - val_accuracy: 0.8429 - val_loss: 1.5795\n",
            "Epoch 295/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 6.8315e-05 - val_accuracy: 0.8571 - val_loss: 1.7811\n",
            "Epoch 296/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 5.2537e-05 - val_accuracy: 0.8571 - val_loss: 1.6941\n",
            "Epoch 297/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.3736e-05 - val_accuracy: 0.8571 - val_loss: 1.7249\n",
            "Epoch 298/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 5.4059e-05 - val_accuracy: 0.8571 - val_loss: 1.8047\n",
            "Epoch 299/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 6.2756e-05 - val_accuracy: 0.8429 - val_loss: 1.5873\n",
            "Epoch 300/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 7.2229e-05 - val_accuracy: 0.8571 - val_loss: 1.8141\n",
            "Epoch 301/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 7.8702e-05 - val_accuracy: 0.8571 - val_loss: 1.7210\n",
            "Epoch 302/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 5.8878e-05 - val_accuracy: 0.8571 - val_loss: 1.7580\n",
            "Epoch 303/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 6.9179e-05 - val_accuracy: 0.8571 - val_loss: 1.7738\n",
            "Epoch 304/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.9598e-05 - val_accuracy: 0.8429 - val_loss: 1.6623\n",
            "Epoch 305/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 7.2251e-05 - val_accuracy: 0.8429 - val_loss: 1.6371\n",
            "Epoch 306/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 8.1827e-05 - val_accuracy: 0.8571 - val_loss: 1.9222\n",
            "Epoch 307/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 8.4773e-05 - val_accuracy: 0.8429 - val_loss: 1.6567\n",
            "Epoch 308/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.4221e-05 - val_accuracy: 0.8429 - val_loss: 1.6889\n",
            "Epoch 309/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.8363e-05 - val_accuracy: 0.8571 - val_loss: 1.7395\n",
            "Epoch 310/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.4255e-05 - val_accuracy: 0.8429 - val_loss: 1.6957\n",
            "Epoch 311/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.9624e-05 - val_accuracy: 0.8571 - val_loss: 1.7348\n",
            "Epoch 312/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.9902e-05 - val_accuracy: 0.8429 - val_loss: 1.6826\n",
            "Epoch 313/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 6.0079e-05 - val_accuracy: 0.8571 - val_loss: 1.7698\n",
            "Epoch 314/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 4.2631e-05 - val_accuracy: 0.8571 - val_loss: 1.7537\n",
            "Epoch 315/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 3.5346e-05 - val_accuracy: 0.8571 - val_loss: 1.8059\n",
            "Epoch 316/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 6.0970e-05 - val_accuracy: 0.8571 - val_loss: 1.7439\n",
            "Epoch 317/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.3071e-05 - val_accuracy: 0.8571 - val_loss: 1.7856\n",
            "Epoch 318/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 6.3946e-05 - val_accuracy: 0.8571 - val_loss: 1.6606\n",
            "Epoch 319/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 5.6362e-05 - val_accuracy: 0.8571 - val_loss: 1.7968\n",
            "Epoch 320/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 6.0452e-05 - val_accuracy: 0.8571 - val_loss: 1.7494\n",
            "Epoch 321/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 4.4725e-05 - val_accuracy: 0.8429 - val_loss: 1.6827\n",
            "Epoch 322/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 5.4570e-05 - val_accuracy: 0.8571 - val_loss: 1.9123\n",
            "Epoch 323/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.5778e-05 - val_accuracy: 0.8571 - val_loss: 1.7314\n",
            "Epoch 324/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.5161e-05 - val_accuracy: 0.8571 - val_loss: 1.8000\n",
            "Epoch 325/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.2769e-05 - val_accuracy: 0.8571 - val_loss: 1.8089\n",
            "Epoch 326/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.9128e-05 - val_accuracy: 0.8571 - val_loss: 1.8344\n",
            "Epoch 327/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 5.4351e-05 - val_accuracy: 0.8429 - val_loss: 1.7187\n",
            "Epoch 328/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 3.2649e-05 - val_accuracy: 0.8429 - val_loss: 1.7512\n",
            "Epoch 329/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 3.2823e-05 - val_accuracy: 0.8571 - val_loss: 1.7822\n",
            "Epoch 330/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 3.6189e-05 - val_accuracy: 0.8429 - val_loss: 1.7768\n",
            "Epoch 331/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 5.5329e-05 - val_accuracy: 0.8571 - val_loss: 1.8237\n",
            "Epoch 332/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.8966e-05 - val_accuracy: 0.8571 - val_loss: 1.8784\n",
            "Epoch 333/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 5.2324e-05 - val_accuracy: 0.8571 - val_loss: 1.7774\n",
            "Epoch 334/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 3.0230e-05 - val_accuracy: 0.8571 - val_loss: 1.8673\n",
            "Epoch 335/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.3955e-05 - val_accuracy: 0.8571 - val_loss: 1.7678\n",
            "Epoch 336/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 2.9299e-05 - val_accuracy: 0.8571 - val_loss: 1.8123\n",
            "Epoch 337/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 4.5472e-05 - val_accuracy: 0.8571 - val_loss: 1.8381\n",
            "Epoch 338/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.6987e-05 - val_accuracy: 0.8571 - val_loss: 1.8162\n",
            "Epoch 339/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.5325e-05 - val_accuracy: 0.8571 - val_loss: 1.8177\n",
            "Epoch 340/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 3.5905e-05 - val_accuracy: 0.8571 - val_loss: 1.7908\n",
            "Epoch 341/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 4.0113e-05 - val_accuracy: 0.8571 - val_loss: 1.8355\n",
            "Epoch 342/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 2.6225e-05 - val_accuracy: 0.8571 - val_loss: 1.9488\n",
            "Epoch 343/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 4.4720e-05 - val_accuracy: 0.8571 - val_loss: 1.8107\n",
            "Epoch 344/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 3.8916e-05 - val_accuracy: 0.8429 - val_loss: 1.7453\n",
            "Epoch 345/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 1.0000 - loss: 3.6067e-05 - val_accuracy: 0.8571 - val_loss: 1.8359\n",
            "Epoch 346/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 2.9035e-05 - val_accuracy: 0.8429 - val_loss: 1.8087\n",
            "Epoch 347/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 3.4417e-05 - val_accuracy: 0.8429 - val_loss: 1.7982\n",
            "Epoch 348/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.9768e-05 - val_accuracy: 0.8571 - val_loss: 1.8915\n",
            "Epoch 349/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.4767e-05 - val_accuracy: 0.8571 - val_loss: 1.8298\n",
            "Epoch 350/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 2.6726e-05 - val_accuracy: 0.8571 - val_loss: 1.8336\n",
            "Epoch 351/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 3.0331e-05 - val_accuracy: 0.8571 - val_loss: 1.8968\n",
            "Epoch 352/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 4.1632e-05 - val_accuracy: 0.8571 - val_loss: 1.8633\n",
            "Epoch 353/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.5833e-05 - val_accuracy: 0.8571 - val_loss: 1.8778\n",
            "Epoch 354/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.7364e-05 - val_accuracy: 0.8429 - val_loss: 1.7884\n",
            "Epoch 355/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.4674e-05 - val_accuracy: 0.8571 - val_loss: 1.8866\n",
            "Epoch 356/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.4890e-05 - val_accuracy: 0.8571 - val_loss: 1.9092\n",
            "Epoch 357/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 3.3097e-05 - val_accuracy: 0.8571 - val_loss: 1.9156\n",
            "Epoch 358/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 2.3836e-05 - val_accuracy: 0.8429 - val_loss: 1.8367\n",
            "Epoch 359/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 3.6287e-05 - val_accuracy: 0.8429 - val_loss: 1.8257\n",
            "Epoch 360/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 2.7513e-05 - val_accuracy: 0.8571 - val_loss: 1.8874\n",
            "Epoch 361/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1819e-05 - val_accuracy: 0.8571 - val_loss: 1.8674\n",
            "Epoch 362/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 2.0274e-05 - val_accuracy: 0.8429 - val_loss: 1.7808\n",
            "Epoch 363/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 5.8363e-05 - val_accuracy: 0.8571 - val_loss: 2.0951\n",
            "Epoch 364/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 4.1768e-05 - val_accuracy: 0.8429 - val_loss: 1.8716\n",
            "Epoch 365/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 2.7349e-05 - val_accuracy: 0.8429 - val_loss: 1.8060\n",
            "Epoch 366/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 3.3409e-05 - val_accuracy: 0.8571 - val_loss: 1.9995\n",
            "Epoch 367/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 2.9332e-05 - val_accuracy: 0.8571 - val_loss: 1.9515\n",
            "Epoch 368/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.2352e-05 - val_accuracy: 0.8429 - val_loss: 1.8414\n",
            "Epoch 369/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.8708e-05 - val_accuracy: 0.8571 - val_loss: 2.0059\n",
            "Epoch 370/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 3.1060e-05 - val_accuracy: 0.8571 - val_loss: 1.9806\n",
            "Epoch 371/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.2599e-05 - val_accuracy: 0.8429 - val_loss: 1.9207\n",
            "Epoch 372/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 2.5477e-05 - val_accuracy: 0.8571 - val_loss: 2.0260\n",
            "Epoch 373/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 2.3505e-05 - val_accuracy: 0.8429 - val_loss: 1.9094\n",
            "Epoch 374/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 1.7062e-05 - val_accuracy: 0.8429 - val_loss: 1.9132\n",
            "Epoch 375/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.7469e-05 - val_accuracy: 0.8571 - val_loss: 1.9560\n",
            "Epoch 376/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.1133e-05 - val_accuracy: 0.8571 - val_loss: 2.0624\n",
            "Epoch 377/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.0844e-05 - val_accuracy: 0.8429 - val_loss: 1.9268\n",
            "Epoch 378/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.8688e-05 - val_accuracy: 0.8571 - val_loss: 1.9790\n",
            "Epoch 379/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 2.6263e-05 - val_accuracy: 0.8429 - val_loss: 1.9425\n",
            "Epoch 380/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.8936e-05 - val_accuracy: 0.8571 - val_loss: 2.0020\n",
            "Epoch 381/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 1.8778e-05 - val_accuracy: 0.8571 - val_loss: 1.9398\n",
            "Epoch 382/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 2.0835e-05 - val_accuracy: 0.8571 - val_loss: 1.8854\n",
            "Epoch 383/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 2.0656e-05 - val_accuracy: 0.8571 - val_loss: 2.0125\n",
            "Epoch 384/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.0571e-05 - val_accuracy: 0.8429 - val_loss: 1.8910\n",
            "Epoch 385/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.1600e-05 - val_accuracy: 0.8571 - val_loss: 2.0474\n",
            "Epoch 386/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.2872e-05 - val_accuracy: 0.8429 - val_loss: 1.9083\n",
            "Epoch 387/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.8215e-05 - val_accuracy: 0.8571 - val_loss: 1.9893\n",
            "Epoch 388/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 2.4529e-05 - val_accuracy: 0.8571 - val_loss: 2.0807\n",
            "Epoch 389/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 2.4664e-05 - val_accuracy: 0.8571 - val_loss: 2.0874\n",
            "Epoch 390/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 1.6915e-05 - val_accuracy: 0.8429 - val_loss: 1.9365\n",
            "Epoch 391/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.2435e-05 - val_accuracy: 0.8571 - val_loss: 2.0677\n",
            "Epoch 392/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 2.0430e-05 - val_accuracy: 0.8571 - val_loss: 1.9039\n",
            "Epoch 393/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 2.3749e-05 - val_accuracy: 0.8571 - val_loss: 1.9275\n",
            "Epoch 394/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.9638e-05 - val_accuracy: 0.8571 - val_loss: 2.0090\n",
            "Epoch 395/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.6623e-05 - val_accuracy: 0.8571 - val_loss: 1.8551\n",
            "Epoch 396/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 1.5856e-05 - val_accuracy: 0.8571 - val_loss: 1.9057\n",
            "Epoch 397/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 1.8579e-05 - val_accuracy: 0.8571 - val_loss: 2.0896\n",
            "Epoch 398/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 2.0965e-05 - val_accuracy: 0.8429 - val_loss: 1.8486\n",
            "Epoch 399/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.4705e-05 - val_accuracy: 0.8571 - val_loss: 1.9339\n",
            "Epoch 400/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 1.0982e-05 - val_accuracy: 0.8571 - val_loss: 2.0976\n",
            "Epoch 401/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 2.4234e-05 - val_accuracy: 0.8571 - val_loss: 2.0203\n",
            "Epoch 402/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 1.3600e-05 - val_accuracy: 0.8571 - val_loss: 1.9810\n",
            "Epoch 403/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 1.0000 - loss: 1.7962e-05 - val_accuracy: 0.8571 - val_loss: 2.0160\n",
            "Epoch 404/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 1.4267e-05 - val_accuracy: 0.8429 - val_loss: 1.9765\n",
            "Epoch 405/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 1.8161e-05 - val_accuracy: 0.8571 - val_loss: 1.9803\n",
            "Epoch 406/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 1.2564e-05 - val_accuracy: 0.8571 - val_loss: 1.9977\n",
            "Epoch 407/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.9050e-05 - val_accuracy: 0.8429 - val_loss: 1.9845\n",
            "Epoch 408/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 8.8239e-06 - val_accuracy: 0.8571 - val_loss: 2.0590\n",
            "Epoch 409/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 1.9176e-05 - val_accuracy: 0.8429 - val_loss: 1.8855\n",
            "Epoch 410/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 1.3053e-05 - val_accuracy: 0.8429 - val_loss: 1.9087\n",
            "Epoch 411/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 1.4753e-05 - val_accuracy: 0.8429 - val_loss: 1.9400\n",
            "Epoch 412/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 1.4994e-05 - val_accuracy: 0.8429 - val_loss: 2.0062\n",
            "Epoch 413/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 1.8173e-05 - val_accuracy: 0.8429 - val_loss: 1.8556\n",
            "Epoch 414/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 4.8048e-05 - val_accuracy: 0.8714 - val_loss: 1.3828\n",
            "Epoch 415/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7546 - loss: 4.4867 - val_accuracy: 0.6143 - val_loss: 0.6692\n",
            "Epoch 416/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.6179 - loss: 0.6414 - val_accuracy: 0.6286 - val_loss: 0.6516\n",
            "Epoch 417/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.6833 - loss: 0.6112 - val_accuracy: 0.6429 - val_loss: 0.5905\n",
            "Epoch 418/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.6623 - loss: 0.5854 - val_accuracy: 0.7000 - val_loss: 0.6360\n",
            "Epoch 419/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7582 - loss: 0.5185 - val_accuracy: 0.6286 - val_loss: 0.6466\n",
            "Epoch 420/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7700 - loss: 0.5025 - val_accuracy: 0.7429 - val_loss: 0.5550\n",
            "Epoch 421/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.7558 - loss: 0.5045 - val_accuracy: 0.7286 - val_loss: 0.6045\n",
            "Epoch 422/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.7877 - loss: 0.4666 - val_accuracy: 0.7571 - val_loss: 0.5393\n",
            "Epoch 423/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.7954 - loss: 0.4507 - val_accuracy: 0.7571 - val_loss: 0.4989\n",
            "Epoch 424/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.7652 - loss: 0.4539 - val_accuracy: 0.6857 - val_loss: 0.6232\n",
            "Epoch 425/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.7877 - loss: 0.4505 - val_accuracy: 0.7429 - val_loss: 0.5963\n",
            "Epoch 426/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7739 - loss: 0.4637 - val_accuracy: 0.7429 - val_loss: 0.6598\n",
            "Epoch 427/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8112 - loss: 0.3998 - val_accuracy: 0.7000 - val_loss: 0.5812\n",
            "Epoch 428/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8181 - loss: 0.4153 - val_accuracy: 0.7286 - val_loss: 0.6219\n",
            "Epoch 429/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.8374 - loss: 0.3827 - val_accuracy: 0.7143 - val_loss: 0.6626\n",
            "Epoch 430/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.7710 - loss: 0.4635 - val_accuracy: 0.7857 - val_loss: 0.6483\n",
            "Epoch 431/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.8029 - loss: 0.3922 - val_accuracy: 0.7714 - val_loss: 0.5586\n",
            "Epoch 432/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.8688 - loss: 0.3329 - val_accuracy: 0.8000 - val_loss: 0.5030\n",
            "Epoch 433/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8560 - loss: 0.3387 - val_accuracy: 0.7857 - val_loss: 0.5321\n",
            "Epoch 434/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8375 - loss: 0.3587 - val_accuracy: 0.8000 - val_loss: 0.6893\n",
            "Epoch 435/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8536 - loss: 0.3405 - val_accuracy: 0.7714 - val_loss: 0.6339\n",
            "Epoch 436/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.8755 - loss: 0.2872 - val_accuracy: 0.7857 - val_loss: 0.6247\n",
            "Epoch 437/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.8659 - loss: 0.2867 - val_accuracy: 0.8143 - val_loss: 0.5476\n",
            "Epoch 438/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.8600 - loss: 0.2922 - val_accuracy: 0.8714 - val_loss: 0.6314\n",
            "Epoch 439/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.8865 - loss: 0.2887 - val_accuracy: 0.8000 - val_loss: 0.6289\n",
            "Epoch 440/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.9047 - loss: 0.2393 - val_accuracy: 0.8571 - val_loss: 0.4462\n",
            "Epoch 441/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8770 - loss: 0.3014 - val_accuracy: 0.7714 - val_loss: 0.7068\n",
            "Epoch 442/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8957 - loss: 0.2814 - val_accuracy: 0.8429 - val_loss: 0.3922\n",
            "Epoch 443/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.8915 - loss: 0.2700 - val_accuracy: 0.8000 - val_loss: 0.5433\n",
            "Epoch 444/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9072 - loss: 0.2537 - val_accuracy: 0.8429 - val_loss: 0.4460\n",
            "Epoch 445/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.8476 - loss: 0.3257 - val_accuracy: 0.8429 - val_loss: 0.5855\n",
            "Epoch 446/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8646 - loss: 0.2858 - val_accuracy: 0.8714 - val_loss: 0.5397\n",
            "Epoch 447/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8864 - loss: 0.2482 - val_accuracy: 0.8857 - val_loss: 0.4208\n",
            "Epoch 448/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8710 - loss: 0.2857 - val_accuracy: 0.8000 - val_loss: 0.7552\n",
            "Epoch 449/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9158 - loss: 0.2084 - val_accuracy: 0.7143 - val_loss: 0.8184\n",
            "Epoch 450/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8724 - loss: 0.2828 - val_accuracy: 0.8143 - val_loss: 0.6691\n",
            "Epoch 451/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9340 - loss: 0.1873 - val_accuracy: 0.8286 - val_loss: 0.5363\n",
            "Epoch 452/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9290 - loss: 0.1998 - val_accuracy: 0.8714 - val_loss: 0.4459\n",
            "Epoch 453/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.9313 - loss: 0.1884 - val_accuracy: 0.8286 - val_loss: 0.8158\n",
            "Epoch 454/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9207 - loss: 0.1831 - val_accuracy: 0.8429 - val_loss: 0.6874\n",
            "Epoch 455/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9213 - loss: 0.1719 - val_accuracy: 0.7857 - val_loss: 0.8803\n",
            "Epoch 456/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8846 - loss: 0.2320 - val_accuracy: 0.8571 - val_loss: 0.7597\n",
            "Epoch 457/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9368 - loss: 0.1723 - val_accuracy: 0.9000 - val_loss: 0.4315\n",
            "Epoch 458/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9029 - loss: 0.2211 - val_accuracy: 0.8286 - val_loss: 0.6120\n",
            "Epoch 459/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8922 - loss: 0.2737 - val_accuracy: 0.8286 - val_loss: 0.8123\n",
            "Epoch 460/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.9228 - loss: 0.1964 - val_accuracy: 0.8714 - val_loss: 0.7282\n",
            "Epoch 461/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - accuracy: 0.9375 - loss: 0.1742 - val_accuracy: 0.8571 - val_loss: 0.6022\n",
            "Epoch 462/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9231 - loss: 0.1858 - val_accuracy: 0.8429 - val_loss: 0.8315\n",
            "Epoch 463/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9221 - loss: 0.2013 - val_accuracy: 0.8571 - val_loss: 0.8548\n",
            "Epoch 464/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9560 - loss: 0.1386 - val_accuracy: 0.8714 - val_loss: 0.8267\n",
            "Epoch 465/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9616 - loss: 0.1287 - val_accuracy: 0.8429 - val_loss: 0.8583\n",
            "Epoch 466/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.9314 - loss: 0.1658 - val_accuracy: 0.8286 - val_loss: 0.7628\n",
            "Epoch 467/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9584 - loss: 0.1143 - val_accuracy: 0.8286 - val_loss: 0.8755\n",
            "Epoch 468/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9593 - loss: 0.0989 - val_accuracy: 0.8000 - val_loss: 1.3745\n",
            "Epoch 469/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.9472 - loss: 0.1495 - val_accuracy: 0.8571 - val_loss: 0.9669\n",
            "Epoch 470/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9488 - loss: 0.1335 - val_accuracy: 0.7857 - val_loss: 1.5490\n",
            "Epoch 471/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9443 - loss: 0.1185 - val_accuracy: 0.8571 - val_loss: 0.9038\n",
            "Epoch 472/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9684 - loss: 0.0806 - val_accuracy: 0.8286 - val_loss: 1.4664\n",
            "Epoch 473/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9371 - loss: 0.1403 - val_accuracy: 0.8429 - val_loss: 1.1481\n",
            "Epoch 474/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9675 - loss: 0.0942 - val_accuracy: 0.8429 - val_loss: 1.0089\n",
            "Epoch 475/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.9593 - loss: 0.1127 - val_accuracy: 0.8429 - val_loss: 1.0783\n",
            "Epoch 476/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9426 - loss: 0.1215 - val_accuracy: 0.8857 - val_loss: 0.6819\n",
            "Epoch 477/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.9510 - loss: 0.1137 - val_accuracy: 0.8286 - val_loss: 1.1591\n",
            "Epoch 478/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9729 - loss: 0.0880 - val_accuracy: 0.8571 - val_loss: 1.0468\n",
            "Epoch 479/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9877 - loss: 0.0559 - val_accuracy: 0.8571 - val_loss: 1.1569\n",
            "Epoch 480/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.9839 - loss: 0.0568 - val_accuracy: 0.8714 - val_loss: 1.1374\n",
            "Epoch 481/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9884 - loss: 0.0500 - val_accuracy: 0.8571 - val_loss: 1.3524\n",
            "Epoch 482/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9729 - loss: 0.0766 - val_accuracy: 0.8571 - val_loss: 1.3443\n",
            "Epoch 483/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.9920 - loss: 0.0460 - val_accuracy: 0.8286 - val_loss: 1.3777\n",
            "Epoch 484/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.9899 - loss: 0.0498 - val_accuracy: 0.8571 - val_loss: 1.8054\n",
            "Epoch 485/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 102ms/step - accuracy: 0.9815 - loss: 0.0574 - val_accuracy: 0.8143 - val_loss: 1.7833\n",
            "Epoch 486/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9865 - loss: 0.0551 - val_accuracy: 0.8286 - val_loss: 1.8145\n",
            "Epoch 487/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9802 - loss: 0.0750 - val_accuracy: 0.8429 - val_loss: 1.4091\n",
            "Epoch 488/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9929 - loss: 0.0365 - val_accuracy: 0.8571 - val_loss: 1.6064\n",
            "Epoch 489/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9864 - loss: 0.0527 - val_accuracy: 0.8429 - val_loss: 1.1444\n",
            "Epoch 490/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9929 - loss: 0.0383 - val_accuracy: 0.8571 - val_loss: 1.7876\n",
            "Epoch 491/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9918 - loss: 0.0343 - val_accuracy: 0.8571 - val_loss: 1.7076\n",
            "Epoch 492/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - accuracy: 0.9821 - loss: 0.0454 - val_accuracy: 0.8429 - val_loss: 1.3742\n",
            "Epoch 493/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9901 - loss: 0.0523 - val_accuracy: 0.8143 - val_loss: 1.8007\n",
            "Epoch 494/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9777 - loss: 0.0530 - val_accuracy: 0.8429 - val_loss: 1.5884\n",
            "Epoch 495/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9943 - loss: 0.0331 - val_accuracy: 0.8429 - val_loss: 1.8282\n",
            "Epoch 496/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9973 - loss: 0.0252 - val_accuracy: 0.8286 - val_loss: 1.7676\n",
            "Epoch 497/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9933 - loss: 0.0306 - val_accuracy: 0.8286 - val_loss: 1.5557\n",
            "Epoch 498/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9918 - loss: 0.0289 - val_accuracy: 0.8429 - val_loss: 2.3327\n",
            "Epoch 499/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.9927 - loss: 0.0267 - val_accuracy: 0.8429 - val_loss: 2.0760\n",
            "Epoch 500/500\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.9946 - loss: 0.0226 - val_accuracy: 0.8571 - val_loss: 1.7993\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 1.4995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.4994635581970215\n",
            "compile_metrics: 0.75\n",
            "Saving model weights and configuration file\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=./truesample.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-54c7be18ad8b>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./truesample.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=./truesample.h5"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(),  # Optimizer\n",
        "    loss='categorical_crossentropy',  # Loss function\n",
        "    metrics=['accuracy']  # Metrics to track during training\n",
        ")\n",
        "history = model.fit(X_train, y_train, epochs=500,validation_split=0.1)\n",
        "\n",
        "metrics = model.evaluate(X_test, y_test)\n",
        "for metric_i in range(len(model.metrics_names)):\n",
        "    metric_name = model.metrics_names[metric_i]\n",
        "    metric_value = metrics[metric_i]\n",
        "    print('{}: {}'.format(metric_name, metric_value))\n",
        "\n",
        "print(\"Saving model weights and configuration file\")\n",
        "\n",
        "model.save('./sample.h5')\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"truesample.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"./truesample.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sRKWRa8l8XxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}